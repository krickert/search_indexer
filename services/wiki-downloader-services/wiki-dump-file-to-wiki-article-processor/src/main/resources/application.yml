micronaut:
  application:
    name: wiki-downloader
  executors:
    consumer:
      type: fixed
      nThreads: 1
    producer:
      type: fixed
      nThreads: 30
  task:
    scheduled:
      enabled: true
      
consul:
  client:
    registration:
      enabled: true
    defaultZone: ${CONSUL_HOST:localhost}:${CONSUL_PORT:8500}

kafka:
  enabled: true
  schema.registry.url: http://${KAFKA_HOST:localhost}:${KAFKA_PORT:8081}
  key:
    serializer: org.apache.kafka.common.serialization.UUIDSerializer
    deserializer: org.apache.kafka.common.serialization.UUIDDeserializer
  value:
    serializer: io.confluent.kafka.serializers.protobuf.KafkaProtobufSerializer
    deserializer: io.confluent.kafka.serializers.protobuf.KafkaProtobufDeserializer

wikipedia:
  send-only-articles: true
  max-file-concurrency: 4 #number of files you would like to process at the same time.
                          #There is only one thread, so it will process them in sequence but
                          #since it is a very long running job, this is done async